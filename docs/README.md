# ğŸš€ AI OCR Pipeline â€“ Bill Recognition (GUI + Core)
**Authors:** 
- Nguyá»…n Quá»‘c Hiá»‡u 
- ÄoÃ n Trung KiÃªn 
- LÃª Nguyá»…n Gia PhÃºc  
- Phan Quá»‘c Äáº¡i SÆ¡n   
- TÃ´n Tháº¥t Thanh Tuáº¥n 

**Date:** 2025-08-25

This system combines **YOLOv8** (detection), **OCR Model** (primary OCR), and **PaddleOCR** (baseline), all integrated into a modern **PySide6** GUI. This README merges an overview of the pipeline with details on the GUI and project structure.

---

## ğŸ§­ Table of Contents
- [Overview](#overview)
- [GUI Highlights](#gui-highlights)
- [Key Features](#key-features)
- [Quick Start](#quick-start)
- [How to Use](#how-to-use)
- [Architecture & Processing Flow](#architecture--processing-flow)
- [Project Structure](#project-structure)
- [Configuration & Tuning](#configuration--tuning)
- [Performance & Comparison](#performance--comparison)
- [Screenshots](#screenshots)
- [Development & Contributing](#development--contributing)
- [Acknowledgments & Contact](#acknowledgments--contact)

---

## ğŸŒŸ Overview
**Bill OCR System** is an AI application that automatically detects bill/receipt regions and recognizes text with high accuracy. The pipeline consists of:
- **ğŸ¯ YOLO v8**: Detects and crops bill regions from the input image.
- **ğŸ¤– OCR Model**: Performs primary OCR with high accuracy.
- **ğŸ§  PaddleOCR**: Baseline model for cross-checking results.

The GUI (implemented in Vietnamese) uses a modern dark theme and provides realâ€‘time result analytics.

---

## ğŸ¨ GUI Highlights
> This section summarizes what makes the GUI interface special.

### ğŸ–¼ 3â€‘Panel Modern Layout
- **Image Input (~35%)** â€“ select & preview images.
- **YOLO Detection (~35%)** â€“ visualize detection results.
- **OCR Results (~30%)** â€“ displays tabular results & model comparison.

### ğŸ¨ Modern Dark Theme & UX
- Professional dark theme with green accent.
- Modern buttons with hover effects and tables with **colorâ€‘coded confidence**:
  - >0.95: deep green â€¢ >0.85: light green â€¢ >0.7: yellow â€¢ >0.5: orange â€¢ â‰¤0.5: red
- **Collapsible Log Window** and separate realâ€‘time status panels for detection and OCR.
- **Autoâ€‘scaling** images with borders indicating status.

### ğŸ”§ UI/Tech Components
- **QSplitter** for the 3â€‘panel layout.
- **QTabWidget** (tabs: Model Comparison, SVTR v6 Details, PaddleOCR Details).
- **QTableWidget** for detailed results and **QScrollArea** for image viewing.
- Custom CSS on top of the Fusion style.

> These enhancements focus on a responsive UX and clear visualization of both detection and OCR outputs.

---

## ğŸ“‹ Key Features
### ğŸ” Detection & Processing
- Automatic detection (YOLO) â†’ Smart cropping â†’ Preâ€‘processing.
- Dual OCR (SVTR v6 + PaddleOCR) with confidence analysis.

### ğŸ“Š Analytics & Stats
- Compare two OCR engines with multiple performance metrics.
- Intuitive tables and charts for analysis.

### ğŸ› GUI & UX
- Vietnamese UI with realâ€‘time progress and responsive layout.
- Modern interface prioritizing detection and results display.

### ğŸ’¾ Export & Storage
- **Export JSON** files (including bounding boxes, confidence scores, timestamps).
- Batch processing envisaged for history management.

---

## ğŸš€ Quick Start

### 1) Environment Setup
```bash
python 3.10 -m venv venv
pip install -r requirements.txt
```

## ğŸ–¥ System Requirements

- **Python:** 3.10 (tested and recommended)
- **Operating System:** Windows 10/11 (64-bit)
- **GPU (optional):** NVIDIA GPU with CUDA/cuDNN for acceleration (otherwise runs on CPU)
- **RAM:** â‰¥ 8GB recommended for smooth processing

### 2) Run the App
```bash
python run.py gui
python run.py benchmark_ocr
python run.py check_model
```

> After installing the requirements, simply run **python run.py [benchmark_ocr | check_model | gui]** to start the application.

---

## ğŸ® How to Use
1. **Select an Image**: Click â€œğŸ“ Select Imageâ€ (sample images are in `image_test/`).
2. **Process**: Click â€œğŸš€ Processâ€ to run detection and OCR.
3. **Analyze**: Review the results in the â€œModel Comparisonâ€, â€œSVTR v6 Detailsâ€, and â€œPaddleOCR Detailsâ€ tabs.
4. **Export JSON**: Click â€œğŸ’¾ Exportâ€ to save the result (includes metadata).

Streamlined flow: **Select â†’ Process â†’ Analyze â†’ Export**.

---

## ğŸ— Architecture & Processing Flow

### Mermaid â€“ Overall Pipeline
```mermaid
graph TD
    A["ğŸ“ Input Image"]
    A --> B["ğŸ¯ YOLO Detection"]
    B --> C["âš™ï¸ Image Preprocessing"]
    C --> D["ğŸ” DBNet (Text Detection)"]
    D --> E["ğŸ§  SVTR (Text Recognition)"]
    E --> G["ğŸ’¾ Export Results"]
```

### UI Layout (ASCII Diagram)
```
+--------------------------+--------------------------+------------------------+
|    Select / Process /    |      YOLO Detection      |      OCR Analysis      |
|          Export          |   Visualization & Stats  |    Result Comparison   |
+==========================+==========================+========================+
| Image Input              | Detection Display        | Model Comparison       |
| [Original / Cropped]     | with Statistics          | and Detailed Breakdown |
+--------------------------+--------------------------+------------------------+
```

---

## ğŸ“ Project Structure
```
receipt-detection/
â”œâ”€â”€ test_setup.py                         # Environment and dependency check
â”œâ”€â”€ requirements.txt                      # Dependencies list
â”œâ”€â”€ image_test/                           # Sample images for testing
â”œâ”€â”€ gui_result/                           # Folder for exported JSON results (auto-created)
â”œâ”€â”€ benchmark_ocr_result/                 # Folder for exported JSON results (auto-created)
â”œâ”€â”€ src/
â”‚â€ƒâ€ƒâ”œâ”€â”€ gui.py
â”‚â€ƒâ€ƒâ”œâ”€â”€ benchmark_ocr.py
â”‚â€ƒâ€ƒâ””â”€â”€ check_model.py
â”œâ”€â”€ yolo_detect_bill/                     # YOLO detection module and models
â”‚   â””â”€â”€ bill_models.pt                    # YOLO model file (used via subfolder path)
â”œâ”€â”€ svtr/                                 # SVTR module and models
â”‚   â””â”€â”€ model
â”‚       â”œâ”€â”€ inference.pdiparams
|       â”œâ”€â”€ inference.pdiparams.info
|       â”œâ”€â”€ inference.pdmodel
|       â””â”€â”€ inference.yml
â””â”€â”€ dbnet/                                # DBNet module and models
â”‚   â””â”€â”€ model
â”‚       â”œâ”€â”€ inference.pdiparams
|       â”œâ”€â”€ inference.pdiparams.info
|       â”œâ”€â”€ inference.pdmodel
|       â””â”€â”€ inference.yml               
```

---

## âš™ï¸ Configuration & Tuning
Key tunable parameters (typically found in the code):
- **YOLO confidence threshold**: `0.1` (in `OCRProcessingThread`).
- **Image display maximum size**: `600px`.
- **Cropping padding**: `10px` (applied in YOLO detection).

---

## âš¡ Performance & Comparison
| Model        | Texts Detected | Avg Confidence | High Conf (>0.9) | Processing Time |
|--------------|----------------|----------------|------------------|-----------------|
| **OCR Model**  | 44             | 0.931          | 89%              | ~2.3s           |
| **PaddleOCR**| 108            | 0.913          | 67%              | ~1.8s           |

- **OCR Model**: Returns fewer texts but with higher accuracy.
- **PaddleOCR**: Returns more texts with slightly lower overall confidence.
- **Recommendation**: Use a combination to balance coverage and accuracy.

---

## ğŸ–¼ Screenshots
- `docs/screenshots/main_interface.png`
- `docs/screenshots/analysis_results.png`
- `docs/screenshots/yolo_detection.png`
*(Additional screenshots can be added.)*

---

## ğŸ§‘â€ğŸ’» Development & Contributing
**Code Style:** Python 3.8+, PySide6, PEP 8, comprehensive docstrings  
**Contribution Flow:**
1. Fork the repository and create a branch (`feature/*`).
2. Commit & push your changes.
3. Open a Pull Request.

**Bug Reports:** Include OS, Python version, full logs, reproduction steps, and screenshots (if any).

---

## ğŸ™ Acknowledgments & Contact
- **YOLOv8** â€“ Ultralytics
- **OCR Model** â€“ STR research community
- **PaddleOCR** â€“ PaddlePaddle team
- **PySide6/Qt** â€“ Qt team

**Authors:** 
- Nguyá»…n Quá»‘c Hiá»‡u 
- ÄoÃ n Trung KiÃªn 
- LÃª Nguyá»…n Gia PhÃºc  
- Phan Quá»‘c Äáº¡i SÆ¡n   
- TÃ´n Tháº¥t Thanh Tuáº¥n  

Feel free to reach out for questions or contributions.
